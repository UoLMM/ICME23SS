<!doctype html>
<html lang="en-US">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1.0"/>
<title>ICME 2023 Special Session: Quality Enhancement and Assessment for Low-quality Multimedia Data Understanding</title>
 <meta name="description" content="Website for Quality Enhancement and Assessment for Low-quality Multimedia Data Understanding ---">
<link href="css/singlePageTemplate.css" rel="stylesheet" type="text/css">
<!--The following script tag downloads a font from the Adobe Edge Web Fonts server for use within the web page. We recommend that you do not modify it.-->
<script>var __adobewebfontsappname__="dreamweaver"</script>
<script src="http://use.edgefonts.net/source-sans-pro:n2:default.js" type="text/javascript"></script>
<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>
<body>
<!-- Main Container -->

<div class="container"> 
  <!-- Navigation -->
  <header class="header" ><img class="mmimg" src="images/icmelogo.png" />
    <nav>
      <ul>
        <li><a href="#call4paper">Call for Papers</a></li>
        <li><a href="#submission">Submission</a></li>
        <li> <a href="#dates">Important Dates</a></li>
        <li> <a href="#organizers">Organizers</a></li>
      </ul>
    </nav>
</header>

	  <section id="homepage2">
<div align ="center"  style="position: relative; width: 100%;">
<img align ="center" class="pic" src="images/Bg-Pic4.jpg" alt="">
  <div class = "title" ><strong><i>ICME 2023 Special Session</i></strong></div>
  <div class = "subtitle" ><strong>Quality Enhancement and Assessment for Low-quality Multimedia Data Understanding</strong></div>

    <div class = "title3" ><strong>Brisbane, Australia | 10-14 July</strong></div>
</div> 
</section>


  <section id="call4paper">
<div class="stats">
    <h1><strong>Call for Papers</strong></h1>
</div>
<div class="stats_text">
    <p>
      Low-quality multimedia data (including images/videos with low resolution, low illumination, defects, blurriness, etc.) often poses a challenge for content understanding, since many visual task algorithms are developed on a clear image or video data under high resolution and good visibility. Taking the light condition as an example, early research focused on high-quality images or daytime scenes with better illumination and recognition algorithms or other specific tasks. Nevertheless, in practice, more than 90% of criminal activity occurs in low-quality nighttime scenarios, in which the image/video data collected by the surveillance system has low contrast and is of poor quality. </p>
	<p>
		To alleviate this problem, data enhancement techniques (super-resolution, low-light enhancement, derain, and inpainting) have been developed to restore low-quality multimedia data. Efforts are also being made to develop robust content understanding algorithms in adverse weather and lighting conditions. There has also been the development of tools for visual data quality assessment. Even though these topics are mostly studied independently, they are tightly related in terms of ensuring a robust understanding of multimedia content. Therefore, this special session will inspire readers from both academia and industry and facilitate research in computer vision and multimedia for a robust understanding of low-quality data in the broader context of multimedia applications. The aim of this special session is to: 1) bring together leading experts from academia and industry to discuss the current state of the art, challenges, and future steps in quality enhancement and assessment for low-quality multimedia data understanding; 2) call for a coordinated effort to understand the opportunities and challenges emerging in quality enhancement and assessment of low-quality multimedia data; 3) identify key tasks and evaluate the state-of-the-art methods; 4) present innovative methodologies and ideas; 5) propose new real-world low-quality multimedia datasets and discuss future directions. To this purpose, we seek original research papers on the following areas, but not limited to:
    </p>
    <ul class="stats_text_ul">
      <li>Emerging trends in data enhancement and evaluation</li>
      <li>Enhancement for a robust content understanding of low-quality data</li>
      <li>Image/video quality assessment for a robust content understanding of low-quality data</li>
      <li>Assessment-guided visual content enhancement of low-quality data</li>
      <li>Joint embedding learning for enhancement, analysis, and evaluation </li>
      <li>Explainable image/video enhancement methods</li>
		<li>Degradation-aware image/video quality assessment methods</li>
		<li>Real-world low-quality multimedia enhancement datasets</li>
		<li>Real-world low-quality multimedia assessment datasets</li>
    </ul>
</div>
</section>

<section id="submission">
<div class="stats">
    <h1><strong>Paper Submission</strong></h1>
</div>

<div class="stats_text">
	<p>Submission website: <a href="https://cmt3.research.microsoft.com/ICME2023" class="link" target="_blank">https://cmt3.research.microsoft.com/ICME2023</a></p>
    <p>After signing in the ICME 2023 submission site as the author, please choose our Special Session name to submit the paper. Papers must be no longer than 6 pages, including all text, figures, and references. ICME 2023 reviewing is double blind, which means that authors cannot know the names of the reviewers of their papers, and reviewers cannot know the names of the authors. Information that may identify the authors anywhere in the submitted materials must be avoided. In particular, in the submitted pdf paper, the usual list of authors, their institutions, and their contact information must be replaced by the phrase, "Anonymous ICME Submission." Identifying information in the acknowledgments (e.g., co-workers and grant IDs), supplemental materials (e.g., titles in the videos, or attached papers), and links to the authors’ or their institutions’ websites must also be avoided.</p>
<p>Please refer to the <a href="https://www.2023.ieeeicme.org/author-info.php" class="link" target="_blank">main conference site</a> for more submission policies on blinding, supplemental material, presentation guarantee, etc.</p>
</div>

</section>

<section id="dates">
<div class="stats">
    <h1><strong>Important Dates</strong></h1>
</div>

<div class="stats_text">
    <ul  class="stats_text_ul">
      <li>Paper submission deadline: &nbsp&nbsp&nbsp<strong>15th December 2022</strong></li>
      <li>Notification of acceptance: &nbsp&nbsp&nbsp&nbsp <strong>12th March 2023</strong></li>
      <li>Camera ready submission: &nbsp&nbsp&nbsp&nbsp <strong>TBA</strong></li>
    </ul>
</div>
</section>


<section id="organizers">
  <div class="stats">
    <h1><strong>Special Session Organizers</strong></h1>
  </div>
<div class="text-center_organizer">
  <div class="col-xs-2">
      <img class="people-pic" src="images/people_LiangLiao.png" />
    <div class="people-name">
<p class="people-name-name"><a href="https://liaoliang92.github.io/homepage/" class="link" target="_blank">Dr. Liang Liao</a></p>      <p class="people-name-inner">liang.liao AT ntu.edu.sg</p>
      <p class="people-name-outer">NTU, Singapore</p>
    </div>
  </div>

  <div class="col-xs-2">

    <img class="people-pic" src="images/people_leida.png" />
  <div class="people-name">
    <p class="people-name-name"><a  href="https://web.xidian.edu.cn/ldli/en/index.html"  class="link" target="_blank">Prof. Leida Li</a></p>
	  <p class="people-name-inner">ldli AT xidian.edu.cn</p>
    <p class="people-name-outer">Xidian, China</p>
  </div>
  </div>

  <div class="col-xs-2">

    <img class="people-pic" src="images/people_marc.png" />
  <div class="people-name">
    <p class="people-name-name"><a  href="https://www.marc-kastner.com/en"  class="link" target="_blank">Dr. Marc A. Kastner</a></p>
	  <p class="people-name-inner">mkastner AT i.kyoto-u.ac.jp</p>
    <p class="people-name-outer">KyotoU, Japan</p>
  </div>
  </div>

  <div class="col-xs-2">

      <img class="people-pic" src="images/people_chaofeng.png" />
    <div class="people-name">
      <p class="people-name-name"><a  href="https://chaofengc.github.io/"  class="link" target="_blank">Dr. Chaofeng Chen</a></p>
	    <p class="people-name-inner">chaofeng.chen AT ntu.edu.sg</p>
      <p class="people-name-outer">NTU, Singapore</p>
    </div>
  </div>

  <div class="col-xs-2">

      <img class="people-pic" src="images/Satoh.jpg" />
    <div class="people-name">
      <p class="people-name-name"><a  href="http://www.satoh-lab.nii.ac.jp/index.html"  class="link" target="_blank">Prof. Shin'ichi Satoh</a></p>
	    <p class="people-name-inner">satoh AT nii.ac.jp</p>
      <p class="people-name-outer">NII, Japan</p>
    </div>
  </div>
	
	  <div class="col-xs-2">

      <img class="people-pic" src="images/people-Weisi L.jpg" />
    <div class="people-name">
      <p class="people-name-name"><a  href="https://personal.ntu.edu.sg/wslin/Home.html"  class="link" target="_blank">Prof. Weisi Lin</a></p>
	    <p class="people-name-inner">wslin AT ntu.edu.sg</p>
      <p class="people-name-outer">NTU, Singapore</p>
    </div>
  </div>
</div>

</section>
</div>
  <footer class="secondary_header footer">
<div class="copyright">&nbsp</div>
    <div class="copyright">&copy;2023 - <strong>ICME Special Session</strong></div>
<div class="copyright">&nbsp</div>
  </footer>
</body>

</html>
